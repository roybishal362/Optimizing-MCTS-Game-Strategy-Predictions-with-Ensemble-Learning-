{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":197802518,"sourceType":"kernelVersion"},{"sourceId":205389271,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport polars as pl\nimport pandas as pd\nimport plotly.graph_objects as go\npd.options.display.max_rows = None\npd.options.display.max_columns = None\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMRegressor\nimport kaggle_evaluation\nimport kaggle_evaluation.mcts_inference_server\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\nimport kaggle_evaluation.mcts_inference_server\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error as mse","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.610466Z","iopub.execute_input":"2024-11-05T19:40:44.610851Z","iopub.status.idle":"2024-11-05T19:40:44.617932Z","shell.execute_reply.started":"2024-11-05T19:40:44.610814Z","shell.execute_reply":"2024-11-05T19:40:44.617005Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    \n    importances_path = Path('/kaggle/input/mcts-gbdt-select-200-features/importances.csv')    \n    train_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv')\n    batch_size = 65536\n\n    early_stop = 500\n    n_splits = 8\n    color = '#C9A9A6'\n    \n    lgb_w = 0.80\n    lgb_p = {\n        'objective': 'regression',\n        'min_child_samples': 24,\n        'num_iterations': 20000,\n        'learning_rate': 0.07,\n        'extra_trees': True,\n        'reg_lambda': 0.8,\n        'reg_alpha': 0.1,\n        'num_leaves': 64,\n        'metric': 'rmse',\n        'device': 'cpu',\n        'max_depth': 24,\n        'max_bin': 128,\n        'verbose': -1,\n        'seed': 42\n    }\n    \n    ctb_w = 0.30\n    ctb_p = {\n        'loss_function': 'RMSE',\n        'learning_rate': 0.03,\n        'num_trees': 20000,\n        'random_state': 42,\n        'task_type': 'CPU',\n        'reg_lambda': 0.8,\n        'depth': 8\n    }","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.619873Z","iopub.execute_input":"2024-11-05T19:40:44.620616Z","iopub.status.idle":"2024-11-05T19:40:44.631413Z","shell.execute_reply.started":"2024-11-05T19:40:44.620571Z","shell.execute_reply":"2024-11-05T19:40:44.630585Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FE:\n    \n    def __init__(self, batch_size):\n        self.batch_size = batch_size\n        \n    def drop_cols(self, df, bad_cols=None): # bad_cols must be provided when processing the test data\n        \n        # Define redundant columns for model development\n        cols = ['Id', \n                'LudRules', \n                'EnglishRules',\n                'num_wins_agent1',\n                'num_draws_agent1',\n                'num_losses_agent1']\n        \n        df = df.drop([col for col in cols if col in df.columns])\n        \n        # Select and drop columns with 100% null values\n        df = df.drop([col for col in df.columns if df.select(pl.col(col).null_count()).item() == df.height])\n        \n        # Select (if not provided) and drop columns with only one unique value\n        bad_cols = [col for col in df.columns if df.select(pl.col(col).n_unique()).item() == 1] if bad_cols is None else bad_cols\n        df = df.drop(bad_cols)\n        \n        return df, bad_cols\n    \n    def cast_datatypes(self, df):\n        \n        # Set datatype for categorical columns\n        cat_cols = ['GameRulesetName', 'agent1', 'agent2']\n        df = df.with_columns([pl.col(col).cast(pl.String) for col in cat_cols])   \n        \n        # Find numeric columns\n        for col in df.columns:\n            if col not in cat_cols:\n            \n                # Set datatype for a numeric column as per the datatype of the first non-null item\n                val = df.select(pl.col(col).drop_nulls().first()).item()\n                df = df.with_columns(pl.col(col).cast(pl.Int16) if isinstance(val, int) else pl.col(col).cast(pl.Float32))   \n            \n        return df    \n    \n    def info(self, df):\n        \n        print(f'Shape: {df.shape}')   \n        mem = df.estimated_size() / 1024**2\n        print('Memory usage: {:.2f} MB\\n'.format(mem))\n        \n    def apply_fe(self, path):\n        \n        df = pl.read_csv(path, batch_size=self.batch_size)\n        \n        df, bad_cols = self.drop_cols(df)\n        df = self.cast_datatypes(df)\n        self.info(df)\n        \n        cat_cols = [col for col in df.columns if df[col].dtype == pl.String]\n        \n        return df, bad_cols, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.633301Z","iopub.execute_input":"2024-11-05T19:40:44.633617Z","iopub.status.idle":"2024-11-05T19:40:44.646308Z","shell.execute_reply.started":"2024-11-05T19:40:44.633574Z","shell.execute_reply":"2024-11-05T19:40:44.645471Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fe = FE(CFG.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.647316Z","iopub.execute_input":"2024-11-05T19:40:44.647841Z","iopub.status.idle":"2024-11-05T19:40:44.661691Z","shell.execute_reply.started":"2024-11-05T19:40:44.647809Z","shell.execute_reply":"2024-11-05T19:40:44.660819Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MD:\n    \n    def __init__(self, \n                 importances_path, \n                 early_stop, \n                 n_splits, \n                 lgb_w, \n                 lgb_p, \n                 ctb_w, \n                 ctb_p, \n                 color):\n        \n        self.importances_path = importances_path\n        self.early_stop = early_stop\n        self.n_splits = n_splits\n        self.lgb_w = lgb_w\n        self.lgb_p = lgb_p\n        self.ctb_w = ctb_w\n        self.ctb_p = ctb_p\n        self.color = color\n        \n    def plot_cv(self, fold_scores, title):\n        \n        fold_scores = [round(score, 3) for score in fold_scores]\n        mean_score = round(np.mean(fold_scores), 3)\n        std_score = round(np.std(fold_scores), 3)\n\n        fig = go.Figure()\n\n        fig.add_trace(go.Scatter(\n            x = list(range(1, len(fold_scores) + 1)),\n            y = fold_scores,\n            mode = 'markers', \n            name = 'Fold Scores',\n            marker = dict(size = 24, color=self.color, symbol='diamond'),\n            text = [f'{score:.3f}' for score in fold_scores],\n            hovertemplate = 'Fold %{x}: %{text}<extra></extra>',\n            hoverlabel=dict(font=dict(size=16))  \n        ))\n\n        fig.add_trace(go.Scatter(\n            x = [1, len(fold_scores)],\n            y = [mean_score, mean_score],\n            mode = 'lines',\n            name = f'Mean: {mean_score:.3f}',\n            line = dict(dash = 'dash', color = '#FFBF00'),\n            hoverinfo = 'none'\n        ))\n\n        fig.update_layout(\n            title = f'{title} | Cross-Validation RMSE Scores | Variation of CV scores: {mean_score} Â± {std_score}',\n            xaxis_title = 'Fold',\n            yaxis_title = 'RMSE Score',\n            plot_bgcolor = 'rgba(0,0,0,0)',\n            paper_bgcolor = 'rgba(0,0,0,0)',\n            xaxis = dict(\n                gridcolor = 'lightgray',\n                tickmode = 'linear',\n                tick0 = 1,\n                dtick = 1,\n                range = [0.5, len(fold_scores) + 0.5]\n            ),\n            yaxis = dict(gridcolor = 'lightgray')\n        )\n\n        fig.show() \n        \n    def train_model(self, data, cat_cols, title):\n        \n        importances = pd.read_csv(self.importances_path)\n\n        for col in cat_cols:\n            data[col] = data[col].astype('category')\n        \n        # Define features (X), label (y) and grouping column (group) for CV\n        X = data.drop(['utility_agent1'], axis=1)\n        y = data['utility_agent1']\n        group = data['GameRulesetName']\n        \n        cv = GroupKFold(n_splits=self.n_splits)\n        \n        models, scores = [], []\n        \n        # Initialize out-of-fold predictions array\n        oof_preds = np.zeros(len(X))\n        \n        for fold, (train_index, valid_index) in enumerate(cv.split(X, y, group)):\n            \n            drop_features = importances['drop_features'].tolist()\n                \n            X_train, X_valid = X.iloc[train_index].drop(drop_features, axis=1), X.iloc[valid_index].drop(drop_features, axis=1)\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            print(f'Fold {fold+1} | {X_train.shape[0]:,} train rows | {X_valid.shape[0]:,} valid rows | {X_train.shape[1]} features')\n                \n            if title.startswith('LightGBM'):\n\n                model = lgb.LGBMRegressor(**self.lgb_p)\n\n                model.fit(X_train, y_train,\n                          eval_set=[(X_valid, y_valid)],\n                          eval_metric='rmse',\n                          callbacks=[lgb.early_stopping(self.early_stop, verbose=0), lgb.log_evaluation(0)])\n            \n            elif title.startswith('CatBoost'):\n            \n                model = CatBoostRegressor(**self.ctb_p, verbose=0, cat_features=cat_cols)\n\n                model.fit(X_train, y_train,\n                          eval_set=(X_valid, y_valid),\n                          early_stopping_rounds=self.early_stop, verbose=0)\n\n            models.append(model)\n\n            # Store out-of-fold predictions for this fold\n            oof_preds[valid_index] = model.predict(X_valid)\n            score = mse(y_valid, oof_preds[valid_index], squared=False)\n            scores.append(score)\n        \n        self.plot_cv(scores, title)\n        \n        return models, oof_preds\n    \n    def inference(self, data, cat_cols, lgb_models, ctb_models, lgb_models_oof, ctb_models_oof):\n\n        importances = pd.read_csv(self.importances_path)\n            \n        drop_features = importances['drop_features'].tolist()\n        data = data.drop(drop_features, axis=1)\n\n        for col in cat_cols:\n            data[col] = data[col].astype('category')\n                \n        data['lgb_oof_preds'] = np.mean([model.predict(data) for model in lgb_models], axis=0)\n        data['ctb_oof_preds'] = np.mean([model.predict(data) for model in ctb_models], axis=0)\n        \n        lgb_preds = np.mean([model.predict(data) for model in lgb_models_oof], axis=0)  \n        ctb_preds = np.mean([model.predict(data) for model in ctb_models_oof], axis=0)    \n        \n        return lgb_preds * self.lgb_w + ctb_preds * self.ctb_w","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.726835Z","iopub.execute_input":"2024-11-05T19:40:44.727099Z","iopub.status.idle":"2024-11-05T19:40:44.751510Z","shell.execute_reply.started":"2024-11-05T19:40:44.727071Z","shell.execute_reply":"2024-11-05T19:40:44.750489Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md = MD(CFG.importances_path, \n        CFG.early_stop, \n        CFG.n_splits, \n        CFG.lgb_w, \n        CFG.lgb_p, \n        CFG.ctb_w, \n        CFG.ctb_p, \n        CFG.color)","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.753337Z","iopub.execute_input":"2024-11-05T19:40:44.753726Z","iopub.status.idle":"2024-11-05T19:40:44.767943Z","shell.execute_reply.started":"2024-11-05T19:40:44.753678Z","shell.execute_reply":"2024-11-05T19:40:44.767063Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model():\n    \n    global bad_cols, cat_cols, lgb_models, ctb_models, lgb_models_oof, ctb_models_oof\n    \n    train, bad_cols, cat_cols = fe.apply_fe(CFG.train_path)\n    train = train.to_pandas()\n        \n    lgb_models, lgb_oof_preds = md.train_model(train, cat_cols, title='LightGBM')\n    ctb_models, ctb_oof_preds = md.train_model(train, cat_cols, title='CatBoost')\n    \n    train['lgb_oof_preds'] = lgb_oof_preds\n    train['ctb_oof_preds'] = ctb_oof_preds\n    \n    lgb_models_oof, _ = md.train_model(train, cat_cols, title='LightGBM w/ OOF')\n    ctb_models_oof, _ = md.train_model(train, cat_cols, title='CatBoost w/ OOF')","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.768875Z","iopub.execute_input":"2024-11-05T19:40:44.769129Z","iopub.status.idle":"2024-11-05T19:40:44.777741Z","shell.execute_reply.started":"2024-11-05T19:40:44.769100Z","shell.execute_reply":"2024-11-05T19:40:44.776938Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"counter = 0\ndef predict(test, submission):\n    \n    global counter\n    \n    if counter == 0:\n        train_model() \n        \n    counter += 1\n    \n    test, _ = fe.drop_cols(test, bad_cols)\n    test = fe.cast_datatypes(test)\n    test = test.to_pandas()\n    \n    return submission.with_columns(pl.Series('utility_agent1', md.inference(test,\n                                                                            cat_cols, \n                                                                            lgb_models, \n                                                                            ctb_models, \n                                                                            lgb_models_oof, \n                                                                            ctb_models_oof)))","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.778855Z","iopub.execute_input":"2024-11-05T19:40:44.779146Z","iopub.status.idle":"2024-11-05T19:40:44.787775Z","shell.execute_reply.started":"2024-11-05T19:40:44.779115Z","shell.execute_reply":"2024-11-05T19:40:44.786963Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-05T19:40:44.789772Z","iopub.execute_input":"2024-11-05T19:40:44.790370Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}